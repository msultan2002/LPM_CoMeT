# Configuration file for the Sniper simulator

# This file is organized into sections defined in [] brackets as in [section].
# Sections may be hierarchical withsub-sections split by the '/' character as
# in [section/sub_section].
#
# values can be "strings" , numbers, or true/false, existing values
# should indicate the type

# This section controls various high-level simulation parameters.
[general]
arch = intel
mode = 64
magic = false # Enable performance simulation straight away (false), or wait for Roi{Begin,End} magic instruction (true)
roi_script = false # Allow ROI to be set by a script, and ignore Roi{Begin,End} magic instructions
inst_mode_init = cache_only
inst_mode_roi = detailed
inst_mode_end = fast_forward
inst_mode_output = true
syntax = intel # Disassembly syntax (intel, att or xed)
issue_memops_at_functional = false # Issue memory operations to the memory hierarchy as they are executed functionally (Pin front-end only)
num_host_cores = 0 # Number of host cores to use (approximately). 0 = autodetect based on available cores and cpu mask. -1 = no limit (oversubscribe)
enable_signals = false
enable_smc_support = false # Support self-modifying code
enable_pinplay = false # Run with a pinball instead of an application (requires a Pin kit with PinPlay support)
enable_syscall_emulation = true # Emulate system calls, cpuid, rdtsc, etc. (disable when replaying Pinballs)
suppress_stdout = false # Suppress the application's output to stdout
suppress_stderr = false # Suppress the application's output to stderr

# Total number of cores in the simulation
total_cores = 16

enable_icache_modeling = false

# This section is used to fine-tune the logging information. The logging may
# be disabled for performance runs or enabled for debugging.
[log]
enabled = false
stack_trace = false
disabled_modules = ""
enabled_modules = ""
mutex_trace = false
pin_codecache_trace = false
circular_log = false

[progress_trace]
enabled = false
interval = 5000
filename = ""

[clock_skew_minimization]
scheme = barrier
report = false

[clock_skew_minimization/barrier]
quantum = 100                         # Synchronize after every quantum (ns)

# This section describes parameters for the core model
[perf_model/core]
frequency = 1        # In GHz
frequency = 3.5        # In GHz
#frequency = 1        # cfg:1GHz
#frequency = 2        # cfg:2GHz
#frequency = 2.7        # cfg:2.7GHz
#frequency = 3        # cfg:3GHz
#frequency = 3.2        # cfg:3.2GHz
#frequency = 3.5        # cfg:3.5GHz
#frequency = 3.7        # cfg:3.7GHz
#frequency = 3.9        # cfg:QU
#frequency = 4        # cfg:4GHz
#frequency = 4.1        # cfg:4.1GHz
#frequency = 4.2        # cfg:4.2GHz
#frequency = 5        # cfg:5GHz
type = oneipc        # Valid models are oneipc, interval, rob
logical_cpus = 1     # Number of SMT threads per core

[perf_model/core/interval_timer]
#dispatch_width = 4
#window_size = 96
issue_contention = true
num_outstanding_loadstores = 8
memory_dependency_granularity = 8 # In bytes
lll_dependency_granularity = 64 # In bytes. Model the MSHR for overlapping misses by adding additional dependencies on long-latency loads using cache-line granularity
lll_cutoff = 30
issue_memops_at_dispatch = false # Issue memory operations to the cache hierarchy at dispatch (true) or at fetch (false)

# This section describes the number of cycles for
# various arithmetic instructions.
[perf_model/core/static_instruction_costs]
add=1
sub=1
mul=3
div=18
fadd=3
fsub=3
fmul=5
fdiv=6
generic=1
jmp=1
string=1
branch=1
dynamic_misc=1
recv=1
sync=0
spawn=0
tlb_miss=0
mem_access=0
delay=0
unknown=0

[perf_model/branch_predictor]
type=one_bit
mispredict_penalty=14 # A guess based on Penryn pipeline depth
size=1024

[perf_model/tlb]
# Penalty of a page walk (in cycles)
penalty = 0
# Page walk is done by separate hardware in parallel to other core activity (true),
# or by the core itself using a serializing instruction (false, e.g. microcode or OS)
penalty_parallel = true

[perf_model/itlb]
size = 0              # Number of I-TLB entries
associativity = 1     # I-TLB associativity

[perf_model/dtlb]
size = 0              # Number of D-TLB entries
associativity = 1     # D-TLB associativity

[perf_model/stlb]
size = 0              # Number of second-level TLB entries
associativity = 1     # S-TLB associativity

[perf_model/l1_icache]
perfect = false
passthrough = false
coherent = true
cache_block_size = 64
cache_size = 32 # in KB
associativity = 4
address_hash = mask
replacement_policy = lru
data_access_time = 3
tags_access_time = 1
perf_model_type = parallel
writeback_time = 0    # Extra time required to write back data to a higher cache level
dvfs_domain = core    # Clock domain: core or global
shared_cores = 1      # Number of cores sharing this cache
next_level_read_bandwidth = 0 # Read bandwidth to next-level cache, in bits/cycle, 0 = infinite
prefetcher = none

[perf_model/l1_dcache]
perfect = false
passthrough = false
cache_block_size = 64
cache_size = 32 # in KB
associativity = 4
address_hash = mask
replacement_policy = lru
data_access_time = 3
tags_access_time = 1
perf_model_type = parallel
writeback_time = 0    # Extra time required to write back data to a higher cache level
dvfs_domain = core    # Clock domain: core or global
shared_cores = 1      # Number of cores sharing this cache
outstanding_misses = 0
next_level_read_bandwidth = 0 # Read bandwidth to next-level cache, in bits/cycle, 0 = infinite
prefetcher = none

[perf_model/l2_cache]
perfect = false
passthrough = false
cache_block_size = 64 # in bytes
cache_size = 512 # in KB
associativity = 8
address_hash = mask
replacement_policy = lru
data_access_time = 9
tags_access_time = 3  # This is just a guess for Penryn
perf_model_type = parallel
writeback_time = 0    # Extra time required to write back data to a higher cache level
dvfs_domain = core    # Clock domain: core or global
shared_cores = 1      # Number of cores sharing this cache
prefetcher = none     # Prefetcher type
next_level_read_bandwidth = 0 # Read bandwidth to next-level cache, in bits/cycle, 0 = infinite

[perf_model/l3_cache]
perfect = false
passthrough = false

[perf_model/l4_cache]
perfect = false
passthrough = false

[perf_model/llc]
evict_buffers = 8

[perf_model/fast_forward]
model = oneipc        # Performance model during fast-forward (none, oneipc)

[perf_model/fast_forward/oneipc]
interval = 100000     # Barrier quantum in fast-forward, in ns
include_memory_latency = true # Increment time by memory latency
include_branch_misprediction = false # Increment time on branch misprediction

[core]
spin_loop_detection = false

[core/light_cache]
num = 0

[core/cheetah]
enabled = false
min_size_bits = 10
max_size_bits_local = 30
max_size_bits_global = 36

[core/hook_periodic_ins]
ins_per_core = 10000  # After how many instructions should each core increment the global HPI counter
ins_global = 1000000  # Aggregate number of instructions between HOOK_PERIODIC_INS callbacks

[caching_protocol]
type = parametric_dram_directory_msi
variant = mesi                            # msi, mesi or mesif

[perf_model/dram_directory]
total_entries = 16384
associativity = 16
max_hw_sharers = 64                       # number of sharers supported in hardware (ignored if directory_type = full_map)
directory_type = full_map                 # Supported (full_map, limited_no_broadcast, limitless)
home_lookup_param = 6                     # Granularity at which the directory is stripped across different cores
directory_cache_access_time = 10          # Tag directory lookup time (in cycles)
locations = dram                          # dram: at each DRAM controller, llc: at master cache locations, interleaved: every N cores (see below)
interleaving = 1                          # N when locations=interleaved

[perf_model/dram_directory/limitless]
software_trap_penalty = 200               # number of cycles added to clock when trapping into software (pulled number from Chaiken papers, which explores 25-150 cycle penalties)

[perf_model/dram]
type = constant                           # DRAM performance model type: "constant" or a "normal" distribution
latency = 100                             # In nanoseconds
latency = 15                             # In nanoseconds
latency_lowpower = 600                   # In nanoseconds. Needs to be defined, but will only be used for dram DTM.
latency_lowpower = 6000                   # In nanoseconds. Needs to be defined, but will only be used for dram DTM.
#latency_lowpower = 600                   # cfg:low600
latency_lowpower = 450                   # cfg:low450
#latency_lowpower = 40                   # cfg:low40
#latency_lowpower = 24                   # cfg:low24
#latency_lowpower = 45                   # cfg:low45
#latency_lowpower = 6000                   # cfg:low6000
per_controller_bandwidth = 5              # In GB/s
num_controllers = -1                      # Total Bandwidth = per_controller_bandwidth * num_controllers
controllers_interleaving = 0              # If num_controllers == -1, place a DRAM controller every N cores
controller_positions = ""
direct_access = false                     # Access DRAM controller directly from last-level cache (only when there is a single LLC)

[perf_model/dram/lowpower]                       
#lpm_dynamic_power = 0.1                    # as a fraction of normal power mode.
lpm_dynamic_power = 0.299                   # as a fraction of normal power mode.
lpm_dynamic_power = 0.1                    # cfg:low450
lpm_leakage_power = 0.01                    # as a fraction of normal power mode.

[perf_model/dram/normal]
standard_deviation = 0                    # The standard deviation, in nanoseconds, of the normal distribution

[perf_model/dram/cache]
enabled = false

[perf_model/dram/queue_model]
enabled = true
type = history_list

[perf_model/nuca]
enabled = false

[perf_model/sync]
reschedule_cost = 0 # In nanoseconds

# This describes the various models used for the different networks on the core
[network]
# Valid Networks :
# 1) magic
# 2) emesh_hop_counter, emesh_hop_by_hop
# 3) bus
memory_model_1 = emesh_hop_counter
system_model = magic
collect_traffic_matrix = false

[network/emesh_hop_counter]
link_bandwidth = 64 # In bits/cycles
hop_latency = 2

[network/emesh_hop_by_hop]
link_bandwidth = 64   # In bits/cycle
hop_latency = 2       # In cycles
concentration = 1     # Number of cores per network stop
dimensions = 2        # Dimensions (1 for line/ring, 2 for 2-D mesh/torus)
wrap_around = false   # Use wrap-around links (false for line/mesh, true for ring/torus)
size = ""             # ":"-separated list of size for each dimension, default = auto

[network/emesh_hop_by_hop/queue_model]
enabled = true
type = history_list
[network/emesh_hop_by_hop/broadcast_tree]
enabled = false

[network/bus]
ignore_local_traffic = true # Do not count traffic between core and directory on the same tile

[network/bus/queue_model]
type=contention

[queue_model/basic]
moving_avg_enabled = true
moving_avg_window_size = 1024
moving_avg_type = arithmetic_mean

[queue_model/history_list]
# Uses the analytical model (if enabled) to calculate delay if cannot be calculated using the history list
max_list_size = 100
analytical_model_enabled = true

[queue_model/windowed_mg1]
window_size = 1000        # In ns. A few times the barrier quantum should be a good choice

[dvfs]
type = simple
transition_latency = 0 # In nanoseconds

[dvfs/simple]
cores_per_socket = 1

[bbv]
sampling = 0 # Defines N to skip X samples with X uniformely distributed between 0..2*N, so on average 1/N samples

[loop_tracer]
#base_address = 0 # Start address in hex (without 0x)
iter_start = 0
iter_count = 36

[osemu]
pthread_replace = false   # Emulate pthread_{mutex|cond|barrier} functions (false: user-space code is simulated, SYS_futex is emulated)
nprocs = 0                # Overwrite emulated get_nprocs() call (default: return simulated number of cores)
clock_replace = true      # Whether to replace gettimeofday() and friends to return simulated time rather than host wall time
time_start = 1337000000   # Simulator startup time ("time zero") for emulated gettimeofday()

[traceinput]
enabled = false
address_randomization = false # Randomize upper address bits on a per-application basis to avoid cache set contention when running multiple copies of the same trace
stop_with_first_app = true    # Simulation ends when first application ends (else: when last application ends)
restart_apps = false          # When stop_with_first_app=false, whether to restart applications until the longest-running app completes for the first time
mirror_output = false
trace_prefix = ""             # Disable trace file prefixes (for trace and response fifos) by default
num_runs = 1                  # Add 1 for warmup, etc

[scheduler]
type = pinned  # default
type = open  # cfg:open
#type = pinned  # cfg:pinned

[scheduler/open]
logic = first_unused #Set the scheduling algorithm used. Currently supported: first_unused.
epoch = 10000000	#Set the scheduling epoch in ns; granularity at which open scheduler is called.
queuePolicy = FIFO	#Set the queuing policy. Currently support: FIFO.
distribution = explicit #Set the arrival distribution of open workload. Currently supported: uniform, poisson, explicit
distributionSeed = 815 #Set the seed for the random distribution (for repeatability). Use 0 to generate a seed. Only used with 'poisson'
arrivalRate = 1	#Set the rate at which tasks arrive together (number of tasks that arrive together).
arrivalInterval = 10000000 #Set the (expected) interval between two arrivals in nano seconds. Only used with 'uniform', 'poisson'
explicitArrivalTimes=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0    # Only used with 'explicit'
core_mask = 1  # Mask of cores on which threads can be scheduled (default: 1, all cores)
preferred_core = -1  # -1 is used to detect the end of the preferred order

[scheduler/open/migration] 
logic = off  # set the migration algorithm used.
epoch = 1000000

[scheduler/open/dvfs]
logic = off  # set the DVFS algorithm used. Possible algorithms: off (no DVFS), constFreq
#logic = constFreq  # cfg:constFreq
#logic = ondemand  # cfg:ondemand
#logic = glsvlsi  # cfg:glsvlsi
#logic = date15  # cfg:date15
#logic = pid  # cfg:pid
#logic = tsp  # cfg:tsp
#logic = ttsp  # cfg:ttsp
min_frequency = 1.0
max_frequency = 4.0
frequency_step_size = 0.1
dvfs_epoch = 1000000


[scheduler/open/dram]
logic = off  # set the memory dtm algorithm used. Possible algorithms: off (no dram policy), lowpower. Dram policy requires open scheduler and constant dram perf model
logic = lowpower #cfg:lowpower
logic = lowpower #cfg:lowpower
#logic = staticlow #cfg:staticlow
dram_epoch = 1000000


[scheduler/open/coreMemDTM]
logic = off
#logic = coreMemDTM #cfg:coreMemDTM
up_threshold = 0.7
down_threshold = 0.3
#dtm_cricital_core_temperature = 65  #cfg:cl75
#dtm_recovered_core_temperature = 60 #cfg:cl75
#dtm_critical_mem_temperature = 75   #cfg:cl75
#dtm_recovered_mem_temperature = 70  #cfg:cl75

#dtm_cricital_core_temperature = 64  #cfg:cl70
#dtm_recovered_core_temperature = 60 #cfg:cl70
#dtm_critical_mem_temperature = 70   #cfg:cl70
#dtm_recovered_mem_temperature = 67  #cfg:cl70

#dtm_cricital_core_temperature = 70  #cfg:cl80
#dtm_recovered_core_temperature = 65 #cfg:cl80
#dtm_critical_mem_temperature = 80   #cfg:cl80
#dtm_recovered_mem_temperature = 75  #cfg:cl80
coreMemDTM_epoch = 1000000
bank_mode_trace_file = bank_mode.trace # name of the file to store the dram bank power modes
full_bank_mode_trace_file = full_bank_mode.trace # name of the file to store the dram bank power modes


# bank_mode_trace_file = bank_mode.trace # name of the file to store the dram bank power modes
# full_bank_mode_trace_file = full_bank_mode.trace # name of the file to store the dram bank power modes

[scheduler/open/dram/dtm] 
dtm_critical_temperature = 80 
dtm_recovered_temperature = 75 
dtm_critical_temperature = 75 #cfg:l75
dtm_recovered_temperature = 70 #cfg:l75

#dtm_critical_temperature = 70 #cfg:l70
#dtm_recovered_temperature = 67 #cfg:l70

#dtm_critical_temperature = 80 #cfg:l80
#dtm_recovered_temperature = 75 #cfg:l80
#off_bank_number = 16
#off_bank_number = 2 # cfg:2N
#off_bank_number = 4 # cfg:4N
#off_bank_number = 8 # cfg:8N
#off_bank_number = 16 # cfg:16N
#off_bank_number = 32 # cfg:32N
#off_bank_number = 48 # cfg:48N
#off_bank_number = 0 # cfg:0N
#off_bank_number = 1 # cfg:1N
#off_bank_number = 2 # cfg:2N
#off_bank_number = 3 # cfg:3N
#off_bank_number = 4 # cfg:4N
#off_bank_number = 5 # cfg:5N
#off_bank_number = 6 # cfg:6N
#off_bank_number = 7 # cfg:7N
#off_bank_number = 8 # cfg:8N
#off_bank_number = 9 # cfg:9N
#off_bank_number = 10 # cfg:10N
#off_bank_number = 11 # cfg:11N
#off_bank_number = 12 # cfg:12N
#off_bank_number = 13 # cfg:13N
#off_bank_number = 14 # cfg:14N
#off_bank_number = 15 # cfg:15N
#off_bank_number = 16 # cfg:16N
#off_bank_number = 17 # cfg:17N
#off_bank_number = 18 # cfg:18N
#off_bank_number = 19 # cfg:19N
#off_bank_number = 20 # cfg:20N
#off_bank_number = 21 # cfg:21N
#off_bank_number = 22 # cfg:22N
#off_bank_number = 23 # cfg:23N
#off_bank_number = 24 # cfg:24N
#off_bank_number = 25 # cfg:25N
#off_bank_number = 26 # cfg:26N
#off_bank_number = 27 # cfg:27N
#off_bank_number = 28 # cfg:28N
#off_bank_number = 29 # cfg:29N
#off_bank_number = 20 # cfg:20N
#off_bank_number = 21 # cfg:21N
#off_bank_number = 22 # cfg:22N
#off_bank_number = 23 # cfg:23N
#off_bank_number = 24 # cfg:24N
#off_bank_number = 25 # cfg:25N
#off_bank_number = 26 # cfg:26N
#off_bank_number = 27 # cfg:27N
#off_bank_number = 28 # cfg:28N
#off_bank_number = 29 # cfg:29N
#off_bank_number = 30 # cfg:30N
#off_bank_number = 31 # cfg:31N
#off_bank_number = 32 # cfg:32N
#off_bank_number = 33 # cfg:33N
#off_bank_number = 34 # cfg:34N
#off_bank_number = 35 # cfg:35N
#off_bank_number = 36 # cfg:36N
#off_bank_number = 37 # cfg:37N
#off_bank_number = 38 # cfg:38N
#off_bank_number = 39 # cfg:39N
#off_bank_number = 40 # cfg:40N
#off_bank_number = 41 # cfg:41N
#off_bank_number = 42 # cfg:42N
#off_bank_number = 43 # cfg:43N
#off_bank_number = 44 # cfg:44N
#off_bank_number = 45 # cfg:45N
#off_bank_number = 46 # cfg:46N
#off_bank_number = 47 # cfg:47N
#off_bank_number = 48 # cfg:48N
#off_bank_number = 49 # cfg:49N
#off_bank_number = 50 # cfg:50N
#off_bank_number = 51 # cfg:51N
#off_bank_number = 52 # cfg:52N
#off_bank_number = 53 # cfg:53N
#off_bank_number = 54 # cfg:54N
#off_bank_number = 55 # cfg:55N
#off_bank_number = 56 # cfg:56N
#off_bank_number = 57 # cfg:57N
#off_bank_number = 58 # cfg:58N
#off_bank_number = 59 # cfg:59N
#off_bank_number = 60 # cfg:60N
#off_bank_number = 61 # cfg:61N
#off_bank_number = 62 # cfg:62N
#off_bank_number = 63 # cfg:63N
#off_bank_number = 64 # cfg:64N
#off_bank_number = 65 # cfg:65N
#off_bank_number = 66 # cfg:66N
#off_bank_number = 67 # cfg:67N
#off_bank_number = 68 # cfg:68N
#off_bank_number = 69 # cfg:69N
#off_bank_number = 70 # cfg:70N
#off_bank_number = 71 # cfg:71N
#off_bank_number = 72 # cfg:72N
#off_bank_number = 73 # cfg:73N
#off_bank_number = 74 # cfg:74N
#off_bank_number = 75 # cfg:75N
#off_bank_number = 76 # cfg:76N
#off_bank_number = 77 # cfg:77N
#off_bank_number = 78 # cfg:78N
#off_bank_number = 79 # cfg:79N
#off_bank_number = 80 # cfg:80N
#off_bank_number = 81 # cfg:81N
#off_bank_number = 82 # cfg:82N
#off_bank_number = 83 # cfg:83N
#off_bank_number = 84 # cfg:84N
#off_bank_number = 85 # cfg:85N
#off_bank_number = 86 # cfg:86N
#off_bank_number = 87 # cfg:87N
#off_bank_number = 88 # cfg:88N
#off_bank_number = 89 # cfg:89N
#off_bank_number = 90 # cfg:90N
#off_bank_number = 91 # cfg:91N
#off_bank_number = 92 # cfg:92N
#off_bank_number = 93 # cfg:93N
#off_bank_number = 94 # cfg:94N
#off_bank_number = 95 # cfg:95N
#off_bank_number = 96 # cfg:96N
#off_bank_number = 97 # cfg:97N
#off_bank_number = 98 # cfg:98N
#off_bank_number = 99 # cfg:99N
#off_bank_number = 100 # cfg:100N
#off_bank_number = 101 # cfg:101N
#off_bank_number = 102 # cfg:102N
#off_bank_number = 103 # cfg:103N
#off_bank_number = 104 # cfg:104N
#off_bank_number = 105 # cfg:105N
#off_bank_number = 106 # cfg:106N
#off_bank_number = 107 # cfg:107N
#off_bank_number = 108 # cfg:108N
#off_bank_number = 109 # cfg:109N
#off_bank_number = 110 # cfg:110N
#off_bank_number = 111 # cfg:111N
#off_bank_number = 112 # cfg:112N
#off_bank_number = 113 # cfg:113N
#off_bank_number = 114 # cfg:114N
#off_bank_number = 115 # cfg:115N
#off_bank_number = 116 # cfg:116N
#off_bank_number = 117 # cfg:117N
#off_bank_number = 118 # cfg:118N
#off_bank_number = 119 # cfg:119N
#off_bank_number = 120 # cfg:120N
#off_bank_number = 121 # cfg:121N
#off_bank_number = 122 # cfg:122N
#off_bank_number = 123 # cfg:123N
#off_bank_number = 124 # cfg:124N
#off_bank_number = 125 # cfg:125N
#off_bank_number = 126 # cfg:126N
#off_bank_number = 127 # cfg:127N


bank_mode_trace_file = bank_mode.trace # name of the file to store the dram bank power modes
full_bank_mode_trace_file = full_bank_mode.trace # name of the file to store the dram bank power modes

[scheduler/open/dvfs/constFreq]
#active_core_freq = 1.0  # cfg:1.0GHz
#active_core_freq = 2.0  # cfg:2.0GHz
#active_core_freq = 3.0  # cfg:3.0GHz
#active_core_freq = 4.0  # cfg:4.0GHz
#idle_core_freq = 1.0  # cfg:1.0GHz
#idle_core_freq = 2.0  # cfg:2.0GHz
#idle_core_freq = 3.0  # cfg:3.0GHz
#idle_core_freq = 0.4  # cfg:4.0GHz

[scheduler/open/dvfs/glsvlsi]
up_threshold = 0.7
down_threshold = 0.3
dtm_cricital_temperature = 70
dtm_recovered_temperature = 65

[scheduler/open/dvfs/date15]
up_threshold = 0.7
down_threshold = 0.3
#dtm_cricital_temperature = 75  #cfg:d75
#dtm_recovered_temperature = 70 #cfg:d75
#dtm_cricital_temperature = 80  #cfg:d80
#dtm_recovered_temperature = 75 #cfg:d80

#dtm_cricital_temperature = 70  #cfg:d70
#dtm_recovered_temperature = 67 #cfg:d70

[scheduler/open/dvfs/ondemand]
up_threshold = 0.7
down_threshold = 0.3
# dtm_cricital_temperature = 70
# dtm_recovered_temperature = 65
dtm_cricital_temperature = 80
dtm_recovered_temperature = 78

[scheduler/open/dvfs/pid]
up_threshold = 0.7
down_threshold = 0.3
dtm_cricital_temperature = 70
dtm_recovered_temperature = 65


[scheduler/pinned]
quantum = 1000000         # Scheduler quantum (round-robin for active threads on each core), in nanoseconds
core_mask = 1             # Mask of cores on which threads can be scheduled (default: 1, all cores)
interleaving = 1          # Interleaving of round-robin initial assignment (e.g. 2 => 0,2,4,6,1,3,5,7)

[scheduler/roaming]
quantum = 1000000         # Scheduler quantum (round-robin for active threads on each core), in nanoseconds
core_mask = 1             # Mask of cores on which threads can be scheduled (default: 1, all cores)

[scheduler/static]
core_mask = 1             # Mask of cores on which threads can be scheduled (default: 1, all cores)

[scheduler/big_small]
quantum = 1000000         # Scheduler quantum, in nanoseconds
debug = false

[hooks]
numscripts = 0

[fault_injection]
type = none
injector = none

[routine_tracer]
type = none

[instruction_tracer]
type = none

[sampling]
enabled = false

[core_power]
l3 = false
l2 = false	# Private L2
is = false	# Instruction Scheduler
rf = false	# Register Files
rbb = false	# Result Broadcast Bus
ru = false	# Renaming Unit
bp = false	# Branch Predictor
btb = false	# Branch Target Buffer
ib = false	# Instruction Buffer
id = false	# Instruction Decoder
ic = false	# Instruction Cache
dc = false	# Data Cache 
calu = false # Complex ALU
falu = false # Floating Point ALU
ialu = false # Integer ALU
lu = false 	# Load Unit
su = false 	# Store Unit
mmu = false 	# Memory Management Unit
ifu = false	# Instruction Fetch Unit
lsu = false	# Load Store Unit
eu = false	# Execution Unit
tp = true	# Total Power

[core_thermal]
enabled = true
#enabled = false  # cfg:nothermal
#commenting out below ones temporarily
#floorplan = ../config/hotspot/3D/stack.lcf
thermal_model = ../benchmarks/rc_model.bin
transient_temperature_file = ../benchmarks/all_transient_mem.init
#ambient_temperature = 45
ambient_temperature = 55
max_temperature = 70
inactive_power = 0.73
method = min
#method = max #cfg:max
#method = average #cfg:average
#method = exact #cfg:exact
PB = tsp
#PB = ttsp #cfg:ttsp
tdp = 100
time = 10000000
#time = 20000000 #cfg:20000000
#time = 10000000 #cfg:10000000
#time = 5000000 #cfg:5000000
#time = 1000000 #cfg:1000000
#time = 500000 #cfg:500000
#time = 100000 #cfg:100000
#time = 50000 #cfg:50000




[power]
#technology_node = 22 # nm
vdd = 0  # will be overwritten in energystats.py
static_frequency_a = 2 #in GHz
static_frequency_b = 4 #in GHz
static_power_a = 0.42  # for kingscross-nuca
static_power_b = 0.86  # for kingscross-nuca
